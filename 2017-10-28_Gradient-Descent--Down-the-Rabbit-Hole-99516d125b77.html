<!DOCTYPE html><html><head>
        <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-175038637-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      
      gtag('config', 'UA-175038637-1');
    </script>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Gradient Descent: Down the Rabbit Hole</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Gradient Descent: Down the Rabbit Hole</h1>
</header>
<section data-field="subtitle" class="p-summary">
Manually doing gradient descent for regression.
</section>
<section data-field="body" class="e-content">
<section name="3438" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="aaaf" id="aaaf" class="graf graf--h3 graf--leading graf--title">Gradient Descent: Down the Rabbit Hole</h3><p name="9bcd" id="9bcd" class="graf graf--p graf-after--h3">Manually doing gradient descent for regression.</p><p name="4cdb" id="4cdb" class="graf graf--p graf-after--p">Gradient descent is a method to perform mathematical optimization. You may have heard of or used gradient descent to optimize your models. In this post we will go over:</p><ol class="postList"><li name="2ecf" id="2ecf" class="graf graf--li graf-after--p">What gradient descent is.</li><li name="98c3" id="98c3" class="graf graf--li graf-after--li">Exploring a problem and a cost function</li><li name="243b" id="243b" class="graf graf--li graf-after--li">Walkthrough of gradient descent for regression on that problem</li></ol><p name="3aaf" id="3aaf" class="graf graf--p graf-after--li">I want to keep this post focused on the concepts; there will be code but the focus will be on getting the intuition of gradient descent.</p><h4 name="cb37" id="cb37" class="graf graf--h4 graf-after--p">What is gradient descent?</h4><p name="312d" id="312d" class="graf graf--p graf-after--h4">In machine learning most problems, classification or regression, can be represented as a process of finding some optimal function for predicting an output (target variable, label) from some set of inputs (x1, x2, x3…). One good strategy for optimization is called <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">gradient descent</em></strong>.</p><h4 name="49a3" id="49a3" class="graf graf--h4 graf-after--p">Let’s explore a problem and a cost function</h4><p name="b9f6" id="b9f6" class="graf graf--p graf-after--h4">Here is some sample data from the <a href="https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/cars.html" data-href="https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/cars.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">cars data set</a> (<a href="https://github.com/yvan/nbsblogs/blob/master/data_science_questions/cars.csv" data-href="https://github.com/yvan/nbsblogs/blob/master/data_science_questions/cars.csv" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">you can load my data here</a>). It shows how long it takes to stop a car (dist) for cars moving at various speeds (speed). ‘dist’ is our y variable. ‘speed’ is our x variable. We will try to predict dist from speed.</p><pre name="eacc" id="eacc" class="graf graf--pre graf-after--p">import pandas as pd<br># load the data <br>data = pd.read_csv(&#39;cars.csv&#39;)<br>data.head()</pre><figure name="713a" id="713a" class="graf graf--figure graf-after--pre"><div class="aspectRatioPlaceholder is-locked" style="max-width: 216px; max-height: 372px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 172.2%;"></div><img class="graf-image" data-image-id="1*S4KBtQqf6L5oPQi1Rqy8-w.png" data-width="216" data-height="372" src="img/1_S4KBtQqf6L5oPQi1Rqy8-w.png"></div></figure><p name="b26d" id="b26d" class="graf graf--p graf-after--figure">Our data looks like this, and we want to draw a line through it that is optimized to fit the data as closely as possible:</p><pre name="bfbd" id="bfbd" class="graf graf--pre graf-after--p">plt.scatter(data[&#39;speed&#39;], data[&#39;dist&#39;])<br>plt.xlabel(&#39;speed&#39;)<br>plt.ylabel(&#39;dist&#39;)<br>plt.show()</pre><figure name="a47e" id="a47e" class="graf graf--figure graf-after--pre"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 475px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 67.80000000000001%;"></div><img class="graf-image" data-image-id="1*CWEdUFQOIjytYLOce3rjLw.png" data-width="796" data-height="540" src="img/1_CWEdUFQOIjytYLOce3rjLw.png"></div></figure><p name="0c6e" id="0c6e" class="graf graf--p graf-after--figure">We will make a function with one parameter (w1):</p><figure name="f6b5" id="f6b5" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 272px; max-height: 58px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 21.3%;"></div><img class="graf-image" data-image-id="1*hibpWZpVkI5hJRcKQX1sWA.png" data-width="272" data-height="58" src="img/1_hibpWZpVkI5hJRcKQX1sWA.png"></div></figure><figure name="bdda" id="bdda" class="graf graf--figure graf-after--figure"><div class="aspectRatioPlaceholder is-locked" style="max-width: 250px; max-height: 60px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 24%;"></div><img class="graf-image" data-image-id="1*FJochE06rvfjmmRnURta9g.png" data-width="250" data-height="60" src="img/1_FJochE06rvfjmmRnURta9g.png"></div></figure><p name="ea27" id="ea27" class="graf graf--p graf-after--figure">We will evaluate this model with a cost formula for a single w1:</p><figure name="a435" id="a435" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 462px; max-height: 74px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 16%;"></div><img class="graf-image" data-image-id="1*xcy8lTrcCkgRKpE0VD4FHA.png" data-width="462" data-height="74" src="img/1_xcy8lTrcCkgRKpE0VD4FHA.png"></div></figure><p name="11b1" id="11b1" class="graf graf--p graf-after--figure">We subtract the actual speed from our predictions of speed, square the difference, and average over all examples. The lower a cost value is the better. If we calculate this cost out for many values of w1 we get a ‘cost function.’ This cost function shows different costs for differnet values of w1.</p><p name="8a23" id="8a23" class="graf graf--p graf-after--p">Let’s plug in some data and lets try some <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">w1</em></strong> values to see what our cost function looks like:</p><figure name="c86c" id="c86c" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/yvan/8e6dc9618b21b0465b0eb233b5076d54.js"></script></figure><figure name="94d7" id="94d7" class="graf graf--figure graf-after--figure"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 447px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 63.800000000000004%;"></div><img class="graf-image" data-image-id="1*aA5uBKVxd-qaLcCoqg7kYQ.png" data-width="818" data-height="522" src="img/1_aA5uBKVxd-qaLcCoqg7kYQ.png"></div></figure><p name="1536" id="1536" class="graf graf--p graf-after--figure graf--trailing">Practically speaking we should exepect a positive value for <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">w1</em></strong> as a higher speed should require a longer stopping distance. It looks like the lowest cost value of this regression is around w1=2.6 (right above 2.5). So <code class="markup--code markup--p-code">y=2.6x1</code> is the optimal function for predicting the stopping distance from speed for the cars dataset. So that’s it everyone! This post is over; let’s call it a day!</p></div></div></section><section name="0454" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="1333" id="1333" class="graf graf--p graf--leading">So…it’s actually more complicated than that. Here the cost function can be calculated because our ‘problem space’ (the number of possible combinations of possible parameter and input values) is small. We only have one parameter (w1) and one input (x1). If our prediction function was more complicated (more parameters and more inputs) it would take a long time to compute the actual shape of its cost function and to find the lowest cost. For linear regression calculating the cost function has an O(n³) computation time, where n is the number of features/inputs. With 20 parameters it takes 8000 times longer (20³) to calculate the cost function than for 1 parameter. Most problems in the real world are complicated and are usually represented with many parameters and so have expensive to compute cost functions.</p><h4 name="33bd" id="33bd" class="graf graf--h4 graf-after--p"><strong class="markup--strong markup--h4-strong">Enter Gradient Descent</strong></h4><p name="98ce" id="98ce" class="graf graf--p graf-after--h4">So if it is too expensive to compute the cost function for real world problems how do we find the optimal function? Gradient descent is the process of following a ‘gradient’ downwards to reach the lowest cost. It is a way to solve for the parameter that produces the lowest cost without computing the whole cost function. How can you compute a gradient?</p><p name="23d1" id="23d1" class="graf graf--p graf-after--p">Draw a tangent line from the current point; get the slope of that line (<a href="https://gist.github.com/yvan/4ac67e0eb8998ba3544fa5241f943678" data-href="https://gist.github.com/yvan/4ac67e0eb8998ba3544fa5241f943678" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">code</a>):</p><figure name="f6ac" id="f6ac" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 432px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 61.8%;"></div><img class="graf-image" data-image-id="1*GnrGP_-ru8POxGpPfgHQNA.png" data-width="842" data-height="520" data-is-featured="true" src="img/1_GnrGP_-ru8POxGpPfgHQNA.png"></div></figure><p name="0fa4" id="0fa4" class="graf graf--p graf-after--figure">Compute the derivative and plug in the current point (use the chain rule to calculate the partial derivative of cost wrt. w1):</p><figure name="b408" id="b408" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 464px; max-height: 236px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 50.9%;"></div><img class="graf-image" data-image-id="1*sri0b6OSAzoeFatsI6XfUg.png" data-width="464" data-height="236" src="img/1_sri0b6OSAzoeFatsI6XfUg.png"></div></figure><p name="729b" id="729b" class="graf graf--p graf-after--figure">Once you get the gradient you can subtract it from your current prameter value to move down the cost function. Basically you are calculating the slope towards the lowest cost and then moving you parameter value (w1) in that direction. But you may notice the tangent line above is a bad approximation if you move far enough away from the original point. If you move too far along the tangent line you get the wrong value for w1 and a 0 cost (not actually possible). This is why you just take a ‘small step’ along the direction of the gradient using something called a learning rate. Here the learning rate is 0.001. It keeps you close to your original point and stops you from getting a bad w1. Here we have repeated the gradient dsecent process 15 times (frames =15).</p><figure name="acb0" id="acb0" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/yvan/d58e474560660fa7817e9e05eeb49354.js"></script></figure><p name="c58c" id="c58c" class="graf graf--p graf-after--figure">Starting at w1= -10 and animated the process of fitting the best regression line looks like so (<a href="https://gist.github.com/yvan/1655d98b55587fe326a8ec88281567e2" data-href="https://gist.github.com/yvan/1655d98b55587fe326a8ec88281567e2" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">see code</a>):</p><figure name="63a3" id="63a3" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 432px; max-height: 288px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 66.7%;"></div><img class="graf-image" data-image-id="1*wPr-6BfyHV6uAhHZysAXLA.gif" data-width="432" data-height="288" src="img/1_wPr-6BfyHV6uAhHZysAXLA.gif"></div></figure><p name="a023" id="a023" class="graf graf--p graf-after--figure">Starting at w1 = -10 and animated this process of finding the lowest cost looks like so (<a href="https://gist.github.com/yvan/b6619b4ba3361e29a8decae069e22054" data-href="https://gist.github.com/yvan/b6619b4ba3361e29a8decae069e22054" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">see code</a>):</p><figure name="b48a" id="b48a" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 432px; max-height: 288px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 66.7%;"></div><img class="graf-image" data-image-id="1*M3itE9cb_p0FKsvOkmhoiQ.gif" data-width="432" data-height="288" src="img/1_M3itE9cb_p0FKsvOkmhoiQ.gif"></div></figure><p name="dcb4" id="dcb4" class="graf graf--p graf-after--figure">Notice our gradient becomes 0 and settles on the lowest possible cost value. Also notice how the changes in w1 become smaller near the end as we get close to our optimal value. The lowest cost value ends up being at <code class="markup--code markup--p-code">w1=2.9</code>. So our original estimate of about 2.6 was not too bad. Hopefully you have a more intuitive undestanding of how gradient descent works now!</p><p name="203c" id="203c" class="graf graf--p graf-after--p">Quick tips:</p><ol class="postList"><li name="327b" id="327b" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Stick to well known loss functions.</strong> Early on in this post I tried to simplify the loss function to make this post easier to understand, it turns out this can create complications that cause gradient descent to move away from an optimal point (aka the exploding gradient problem).</li><li name="6082" id="6082" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Make sure to use a differentiable loss function.</strong> If you are using a custom loss function check its differentiability manually or with wolfram alpha. Your loss function should have a computable derivative. If your loss function is not differentiable you can’t use gradient descent.</li><li name="e36a" id="e36a" class="graf graf--li graf-after--li">Brush up on your calculus, specifically chain rule/partial derivatives. Read “<a href="http://djm.cc/library/Calculus_Made_Easy_Thompson.pdf" data-href="http://djm.cc/library/Calculus_Made_Easy_Thompson.pdf" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Calculus Made Easy</a>” if you don’t know calculus. It will help you to prove/derive things for yourself when you need to understand what your code is doing. Calculus is the single most useful tool I learned in school. We probably could have skipped the rest of the ‘curriculum.’</li></ol><p name="7e16" id="7e16" class="graf graf--p graf-after--li graf--trailing">I hope you enjoyed this post of gradient descent. If you want to <a href="https://tinyletter.com/generationmachine" data-href="https://tinyletter.com/generationmachine" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">signup for my newsletter covering marchine learning for video games and see more datascience you can do that here</a>. Have a good day!</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@yvanscher" class="p-author h-card">Yvan Scher</a> on <a href="https://medium.com/p/99516d125b77"><time class="dt-published" datetime="2017-10-28T17:34:47.618Z">October 28, 2017</time></a>.</p><p><a href="https://medium.com/@yvanscher/gradient-descent-down-the-rabbit-hole-99516d125b77" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on June 23, 2020.</p></footer></article></body></html>
